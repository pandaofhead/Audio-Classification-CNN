{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05ceaa10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zw/y7lpjbyd3j7f8j3xd3glytlr0000gn/T/ipykernel_14929/3958821539.py:200: UserWarning: Found 4/5 classes in training data. Increase data size or change random_state.\n",
      "  warnings.warn('Found {}/{} classes in training data. Increase data size or change random_state.'.format(len(set(label_train)), params['N_CLASSES']))\n",
      "/var/folders/zw/y7lpjbyd3j7f8j3xd3glytlr0000gn/T/ipykernel_14929/3958821539.py:202: UserWarning: Found 4/5 classes in validation data. Increase data size or change random_state.\n",
      "  warnings.warn('Found {}/{} classes in validation data. Increase data size or change random_state.'.format(len(set(label_val)), params['N_CLASSES']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763/763 [==============================] - ETA: 0s - loss: 0.4824 - accuracy: 0.8281\n",
      "Epoch 1: val_loss improved from inf to 0.37818, saving model to models/lstm.h5\n",
      "763/763 [==============================] - 33s 42ms/step - loss: 0.4824 - accuracy: 0.8281 - val_loss: 0.3782 - val_accuracy: 0.8770\n",
      "Epoch 2/30\n",
      "  3/763 [..............................] - ETA: 27s - loss: 0.3945 - accuracy: 0.8542"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quanhongjin/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763/763 [==============================] - ETA: 0s - loss: 0.2192 - accuracy: 0.9341\n",
      "Epoch 2: val_loss improved from 0.37818 to 0.22440, saving model to models/lstm.h5\n",
      "763/763 [==============================] - 32s 42ms/step - loss: 0.2192 - accuracy: 0.9341 - val_loss: 0.2244 - val_accuracy: 0.9372\n",
      "Epoch 3/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.1635 - accuracy: 0.9559\n",
      "Epoch 3: val_loss improved from 0.22440 to 0.17286, saving model to models/lstm.h5\n",
      "763/763 [==============================] - 32s 42ms/step - loss: 0.1635 - accuracy: 0.9559 - val_loss: 0.1729 - val_accuracy: 0.9500\n",
      "Epoch 4/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.1302 - accuracy: 0.9648\n",
      "Epoch 4: val_loss improved from 0.17286 to 0.11762, saving model to models/lstm.h5\n",
      "763/763 [==============================] - 32s 42ms/step - loss: 0.1302 - accuracy: 0.9648 - val_loss: 0.1176 - val_accuracy: 0.9691\n",
      "Epoch 5/30\n",
      "762/763 [============================>.] - ETA: 0s - loss: 0.1083 - accuracy: 0.9733\n",
      "Epoch 5: val_loss improved from 0.11762 to 0.09639, saving model to models/lstm.h5\n",
      "763/763 [==============================] - 32s 42ms/step - loss: 0.1082 - accuracy: 0.9734 - val_loss: 0.0964 - val_accuracy: 0.9757\n",
      "Epoch 6/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9795\n",
      "Epoch 6: val_loss did not improve from 0.09639\n",
      "763/763 [==============================] - 32s 42ms/step - loss: 0.0865 - accuracy: 0.9795 - val_loss: 0.1606 - val_accuracy: 0.9516\n",
      "Epoch 7/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9759\n",
      "Epoch 7: val_loss improved from 0.09639 to 0.08816, saving model to models/lstm.h5\n",
      "763/763 [==============================] - 32s 43ms/step - loss: 0.0935 - accuracy: 0.9759 - val_loss: 0.0882 - val_accuracy: 0.9750\n",
      "Epoch 8/30\n",
      "762/763 [============================>.] - ETA: 0s - loss: 0.0816 - accuracy: 0.9813\n",
      "Epoch 8: val_loss did not improve from 0.08816\n",
      "763/763 [==============================] - 32s 42ms/step - loss: 0.0815 - accuracy: 0.9813 - val_loss: 0.1037 - val_accuracy: 0.9691\n",
      "Epoch 9/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9866\n",
      "Epoch 9: val_loss improved from 0.08816 to 0.04670, saving model to models/lstm.h5\n",
      "763/763 [==============================] - 32s 42ms/step - loss: 0.0605 - accuracy: 0.9866 - val_loss: 0.0467 - val_accuracy: 0.9924\n",
      "Epoch 10/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.0636 - accuracy: 0.9871\n",
      "Epoch 10: val_loss did not improve from 0.04670\n",
      "763/763 [==============================] - 33s 43ms/step - loss: 0.0636 - accuracy: 0.9871 - val_loss: 0.0702 - val_accuracy: 0.9822\n",
      "Epoch 11/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9883\n",
      "Epoch 11: val_loss did not improve from 0.04670\n",
      "763/763 [==============================] - 33s 43ms/step - loss: 0.0536 - accuracy: 0.9883 - val_loss: 0.0560 - val_accuracy: 0.9878\n",
      "Epoch 12/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.9884\n",
      "Epoch 12: val_loss did not improve from 0.04670\n",
      "763/763 [==============================] - 33s 43ms/step - loss: 0.0558 - accuracy: 0.9884 - val_loss: 0.0666 - val_accuracy: 0.9859\n",
      "Epoch 13/30\n",
      "762/763 [============================>.] - ETA: 0s - loss: 0.0722 - accuracy: 0.9828\n",
      "Epoch 13: val_loss did not improve from 0.04670\n",
      "763/763 [==============================] - 33s 43ms/step - loss: 0.0721 - accuracy: 0.9828 - val_loss: 0.0573 - val_accuracy: 0.9862\n",
      "Epoch 14/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9950\n",
      "Epoch 14: val_loss did not improve from 0.04670\n",
      "763/763 [==============================] - 33s 43ms/step - loss: 0.0317 - accuracy: 0.9950 - val_loss: 0.0830 - val_accuracy: 0.9799\n",
      "Epoch 15/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9880\n",
      "Epoch 15: val_loss did not improve from 0.04670\n",
      "763/763 [==============================] - 32s 43ms/step - loss: 0.0553 - accuracy: 0.9880 - val_loss: 0.1117 - val_accuracy: 0.9724\n",
      "Epoch 16/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9940\n",
      "Epoch 16: val_loss did not improve from 0.04670\n",
      "763/763 [==============================] - 33s 43ms/step - loss: 0.0317 - accuracy: 0.9940 - val_loss: 0.1388 - val_accuracy: 0.9658\n",
      "Epoch 17/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.9848\n",
      "Epoch 17: val_loss improved from 0.04670 to 0.03553, saving model to models/lstm.h5\n",
      "763/763 [==============================] - 33s 43ms/step - loss: 0.0683 - accuracy: 0.9848 - val_loss: 0.0355 - val_accuracy: 0.9924\n",
      "Epoch 18/30\n",
      "762/763 [============================>.] - ETA: 0s - loss: 0.0469 - accuracy: 0.9898\n",
      "Epoch 18: val_loss improved from 0.03553 to 0.03305, saving model to models/lstm.h5\n",
      "763/763 [==============================] - 33s 43ms/step - loss: 0.0469 - accuracy: 0.9898 - val_loss: 0.0331 - val_accuracy: 0.9947\n",
      "Epoch 19/30\n",
      "762/763 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9947\n",
      "Epoch 19: val_loss improved from 0.03305 to 0.03120, saving model to models/lstm.h5\n",
      "763/763 [==============================] - 33s 43ms/step - loss: 0.0294 - accuracy: 0.9947 - val_loss: 0.0312 - val_accuracy: 0.9941\n",
      "Epoch 20/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9907\n",
      "Epoch 20: val_loss did not improve from 0.03120\n",
      "763/763 [==============================] - 33s 43ms/step - loss: 0.0442 - accuracy: 0.9907 - val_loss: 0.0886 - val_accuracy: 0.9757\n",
      "Epoch 21/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 0.9894\n",
      "Epoch 21: val_loss did not improve from 0.03120\n",
      "763/763 [==============================] - 33s 43ms/step - loss: 0.0463 - accuracy: 0.9894 - val_loss: 0.0574 - val_accuracy: 0.9872\n",
      "Epoch 22/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9952\n",
      "Epoch 22: val_loss did not improve from 0.03120\n",
      "763/763 [==============================] - 33s 43ms/step - loss: 0.0274 - accuracy: 0.9952 - val_loss: 0.0380 - val_accuracy: 0.9928\n",
      "Epoch 23/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9983\n",
      "Epoch 23: val_loss improved from 0.03120 to 0.02008, saving model to models/lstm.h5\n",
      "763/763 [==============================] - 32s 42ms/step - loss: 0.0156 - accuracy: 0.9983 - val_loss: 0.0201 - val_accuracy: 0.9957\n",
      "Epoch 24/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9864\n",
      "Epoch 24: val_loss did not improve from 0.02008\n",
      "763/763 [==============================] - 32s 42ms/step - loss: 0.0553 - accuracy: 0.9864 - val_loss: 0.0305 - val_accuracy: 0.9944\n",
      "Epoch 25/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9891\n",
      "Epoch 25: val_loss did not improve from 0.02008\n",
      "763/763 [==============================] - 32s 43ms/step - loss: 0.0433 - accuracy: 0.9891 - val_loss: 0.0338 - val_accuracy: 0.9918\n",
      "Epoch 26/30\n",
      "762/763 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9979\n",
      "Epoch 26: val_loss did not improve from 0.02008\n",
      "763/763 [==============================] - 33s 43ms/step - loss: 0.0175 - accuracy: 0.9979 - val_loss: 0.0339 - val_accuracy: 0.9921\n",
      "Epoch 27/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9897\n",
      "Epoch 27: val_loss did not improve from 0.02008\n",
      "763/763 [==============================] - 32s 42ms/step - loss: 0.0497 - accuracy: 0.9897 - val_loss: 0.0616 - val_accuracy: 0.9826\n",
      "Epoch 28/30\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9953\n",
      "Epoch 28: val_loss did not improve from 0.02008\n",
      "763/763 [==============================] - 32s 42ms/step - loss: 0.0248 - accuracy: 0.9953 - val_loss: 0.0202 - val_accuracy: 0.9961\n",
      "Epoch 29/30\n",
      "762/763 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9997\n",
      "Epoch 29: val_loss improved from 0.02008 to 0.01615, saving model to models/lstm.h5\n",
      "763/763 [==============================] - 32s 43ms/step - loss: 0.0089 - accuracy: 0.9997 - val_loss: 0.0161 - val_accuracy: 0.9974\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762/763 [============================>.] - ETA: 0s - loss: 0.0657 - accuracy: 0.9846\n",
      "Epoch 30: val_loss did not improve from 0.01615\n",
      "763/763 [==============================] - 32s 42ms/step - loss: 0.0656 - accuracy: 0.9846 - val_loss: 0.0378 - val_accuracy: 0.9914\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import argparse\n",
    "import warnings\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TimeDistributed, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import kapre\n",
    "from kapre.composed import get_melspectrogram_layer\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# models\n",
    "def Conv1D(N_CLASSES=4, SR=16000, DT=1.0):\n",
    "    input_shape = (int(SR*DT), 1)\n",
    "    i = get_melspectrogram_layer(input_shape=input_shape,\n",
    "                                 n_mels=128,\n",
    "                                 pad_end=True,\n",
    "                                 n_fft=512,\n",
    "                                 win_length=400,\n",
    "                                 hop_length=160,\n",
    "                                 sample_rate=SR,\n",
    "                                 return_decibel=True,\n",
    "                                 input_data_format='channels_last',\n",
    "                                 output_data_format='channels_last')\n",
    "    x = LayerNormalization(axis=2, name='batch_norm')(i.output)\n",
    "    x = TimeDistributed(layers.Conv1D(8, kernel_size=(4), activation='tanh'), name='td_conv_1d_tanh')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_1')(x)\n",
    "    x = TimeDistributed(layers.Conv1D(16, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_1')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_2')(x)\n",
    "    x = TimeDistributed(layers.Conv1D(32, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_2')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_3')(x)\n",
    "    x = TimeDistributed(layers.Conv1D(64, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_3')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_4')(x)\n",
    "    x = TimeDistributed(layers.Conv1D(128, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_4')(x)\n",
    "    x = layers.GlobalMaxPooling2D(name='global_max_pooling_2d')(x)\n",
    "    x = layers.Dropout(rate=0.1, name='dropout')(x)\n",
    "    x = layers.Dense(64, activation='relu', activity_regularizer=l2(0.001), name='dense')(x)\n",
    "    o = layers.Dense(N_CLASSES, activation='softmax', name='softmax')(x)\n",
    "    model = Model(inputs=i.input, outputs=o, name='1d_convolution')\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def Conv2D(N_CLASSES=4, SR=16000, DT=1.0):\n",
    "    input_shape = (int(SR*DT), 1)\n",
    "    i = get_melspectrogram_layer(input_shape=input_shape,\n",
    "                                 n_mels=128,\n",
    "                                 pad_end=True,\n",
    "                                 n_fft=512,\n",
    "                                 win_length=400,\n",
    "                                 hop_length=160,\n",
    "                                 sample_rate=SR,\n",
    "                                 return_decibel=True,\n",
    "                                 input_data_format='channels_last',\n",
    "                                 output_data_format='channels_last')\n",
    "    x = LayerNormalization(axis=2, name='batch_norm')(i.output)\n",
    "    x = layers.Conv2D(8, kernel_size=(7,7), activation='tanh', padding='same', name='conv2d_tanh')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_1')(x)\n",
    "    x = layers.Conv2D(16, kernel_size=(5,5), activation='relu', padding='same', name='conv2d_relu_1')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_2')(x)\n",
    "    x = layers.Conv2D(16, kernel_size=(3,3), activation='relu', padding='same', name='conv2d_relu_2')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_3')(x)\n",
    "    x = layers.Conv2D(32, kernel_size=(3,3), activation='relu', padding='same', name='conv2d_relu_3')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_4')(x)\n",
    "    x = layers.Conv2D(32, kernel_size=(3,3), activation='relu', padding='same', name='conv2d_relu_4')(x)\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    x = layers.Dropout(rate=0.2, name='dropout')(x)\n",
    "    x = layers.Dense(64, activation='relu', activity_regularizer=l2(0.001), name='dense')(x)\n",
    "    o = layers.Dense(N_CLASSES, activation='softmax', name='softmax')(x)\n",
    "    model = Model(inputs=i.input, outputs=o, name='2d_convolution')\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def LSTM(N_CLASSES=4, SR=16000, DT=1.0):\n",
    "    input_shape = (int(SR*DT), 1)\n",
    "    i = get_melspectrogram_layer(input_shape=input_shape,\n",
    "                                     n_mels=128,\n",
    "                                     pad_end=True,\n",
    "                                     n_fft=512,\n",
    "                                     win_length=400,\n",
    "                                     hop_length=160,\n",
    "                                     sample_rate=SR,\n",
    "                                     return_decibel=True,\n",
    "                                     input_data_format='channels_last',\n",
    "                                     output_data_format='channels_last',\n",
    "                                     name='2d_convolution')\n",
    "    x = LayerNormalization(axis=2, name='batch_norm')(i.output)\n",
    "    x = TimeDistributed(layers.Reshape((-1,)), name='reshape')(x)\n",
    "    s = TimeDistributed(layers.Dense(64, activation='tanh'),\n",
    "                        name='td_dense_tanh')(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(32, return_sequences=True),\n",
    "                             name='bidirectional_lstm')(s)\n",
    "    x = layers.concatenate([s, x], axis=2, name='skip_connection')\n",
    "    x = layers.Dense(64, activation='relu', name='dense_1_relu')(x)\n",
    "    x = layers.MaxPooling1D(name='max_pool_1d')(x)\n",
    "    x = layers.Dense(32, activation='relu', name='dense_2_relu')(x)\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    x = layers.Dropout(rate=0.2, name='dropout')(x)\n",
    "    x = layers.Dense(32, activation='relu',\n",
    "                         activity_regularizer=l2(0.001),\n",
    "                         name='dense_3_relu')(x)\n",
    "    o = layers.Dense(N_CLASSES, activation='softmax', name='softmax')(x)\n",
    "    model = Model(inputs=i.input, outputs=o, name='long_short_term_memory')\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, wav_paths, labels, sr, dt, n_classes,\n",
    "                 batch_size=32, shuffle=True):\n",
    "        self.wav_paths = wav_paths\n",
    "        self.labels = labels\n",
    "        self.sr = sr\n",
    "        self.dt = dt\n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = True\n",
    "        self.on_epoch_end()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.wav_paths) / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        wav_paths = [self.wav_paths[k] for k in indexes]\n",
    "        labels = [self.labels[k] for k in indexes]\n",
    "\n",
    "        # generate a batch of time data\n",
    "        X = np.empty((self.batch_size, int(self.sr*self.dt), 1), dtype=np.float32)\n",
    "        Y = np.empty((self.batch_size, self.n_classes), dtype=np.float32)\n",
    "\n",
    "        for i, (path, label) in enumerate(zip(wav_paths, labels)):\n",
    "            rate, wav = wavfile.read(path)\n",
    "            X[i,] = wav.reshape(-1, 1)\n",
    "            Y[i,] = to_categorical(label, num_classes=self.n_classes)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.wav_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    src_root = args.src_root\n",
    "    sr = args.sample_rate\n",
    "    dt = args.delta_time\n",
    "    batch_size = args.batch_size\n",
    "    model_type = args.model_type\n",
    "    params = {'N_CLASSES':len(os.listdir(args.src_root)),\n",
    "              'SR':sr,\n",
    "              'DT':dt}\n",
    "    models = {'conv1d':Conv1D(**params),\n",
    "              'conv2d':Conv2D(**params),\n",
    "              'lstm':  LSTM(**params)}\n",
    "    assert model_type in models.keys(), '{} not an available model'.format(model_type)\n",
    "    csv_path = os.path.join('logs', '{}_history.csv'.format(model_type))\n",
    "\n",
    "    wav_paths = glob('{}/**'.format(src_root), recursive=True)\n",
    "    wav_paths = [x.replace(os.sep, '/') for x in wav_paths if '.wav' in x]\n",
    "    classes = sorted(os.listdir(args.src_root))\n",
    "    le = LabelEncoder()\n",
    "    le.fit(classes)\n",
    "    labels = [os.path.split(x)[0].split('/')[-1] for x in wav_paths]\n",
    "    labels = le.transform(labels)\n",
    "    wav_train, wav_val, label_train, label_val = train_test_split(wav_paths,\n",
    "                                                                  labels,\n",
    "                                                                  test_size=0.2,\n",
    "                                                                  random_state=0)\n",
    "\n",
    "    assert len(label_train) >= args.batch_size, 'Number of train samples must be >= batch_size'\n",
    "    if len(set(label_train)) != params['N_CLASSES']:\n",
    "        warnings.warn('Found {}/{} classes in training data. Increase data size or change random_state.'.format(len(set(label_train)), params['N_CLASSES']))\n",
    "    if len(set(label_val)) != params['N_CLASSES']:\n",
    "        warnings.warn('Found {}/{} classes in validation data. Increase data size or change random_state.'.format(len(set(label_val)), params['N_CLASSES']))\n",
    "\n",
    "    tg = DataGenerator(wav_train, label_train, sr, dt,\n",
    "                       params['N_CLASSES'], batch_size=batch_size)\n",
    "    vg = DataGenerator(wav_val, label_val, sr, dt,\n",
    "                       params['N_CLASSES'], batch_size=batch_size)\n",
    "    model = models[model_type]\n",
    "    cp = ModelCheckpoint('models/{}.h5'.format(model_type), monitor='val_loss',\n",
    "                         save_best_only=True, save_weights_only=False,\n",
    "                         mode='auto', save_freq='epoch', verbose=1)\n",
    "    csv_logger = CSVLogger(csv_path, append=False)\n",
    "    model.fit(tg, validation_data=vg,\n",
    "              epochs=30, verbose=1,\n",
    "              callbacks=[csv_logger, cp])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Audio Classification Training')\n",
    "    parser.add_argument('--model_type', type=str, default='lstm',\n",
    "                        help='model to run. i.e. conv1d, conv2d, lstm')\n",
    "    \n",
    "    # replace with your absolute file path here\n",
    "    parser.add_argument('--src_root', type=str, default='/Users/quanhongjin/Documents/Cornell Tech/CS5785/Porject/clean',\n",
    "                        help='directory of audio files in total duration')\n",
    "    parser.add_argument('--batch_size', type=int, default=16,\n",
    "                        help='batch size')\n",
    "    parser.add_argument('--delta_time', '-dt', type=float, default=1.0,\n",
    "                        help='time in seconds to sample audio')\n",
    "    parser.add_argument('--sample_rate', '-sr', type=int, default=16000,\n",
    "                        help='sample rate of clean audio')\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    train(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb864b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbimporter\n",
      "  Downloading nbimporter-0.3.4-py3-none-any.whl (4.9 kB)\n",
      "Installing collected packages: nbimporter\n",
      "Successfully installed nbimporter-0.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nbimporter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6338493a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
