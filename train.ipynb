{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05ceaa10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zw/y7lpjbyd3j7f8j3xd3glytlr0000gn/T/ipykernel_2714/1108093828.py:200: UserWarning: Found 14/15 classes in training data. Increase data size or change random_state.\n",
      "  warnings.warn('Found {}/{} classes in training data. Increase data size or change random_state.'.format(len(set(label_train)), params['N_CLASSES']))\n",
      "/var/folders/zw/y7lpjbyd3j7f8j3xd3glytlr0000gn/T/ipykernel_2714/1108093828.py:202: UserWarning: Found 14/15 classes in validation data. Increase data size or change random_state.\n",
      "  warnings.warn('Found {}/{} classes in validation data. Increase data size or change random_state.'.format(len(set(label_val)), params['N_CLASSES']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858/858 [==============================] - ETA: 0s - loss: 0.8254 - accuracy: 0.7547\n",
      "Epoch 1: val_loss improved from inf to 0.47459, saving model to models/lstm.h5\n",
      "858/858 [==============================] - 39s 44ms/step - loss: 0.8254 - accuracy: 0.7547 - val_loss: 0.4746 - val_accuracy: 0.8618\n",
      "Epoch 2/30\n",
      "  3/858 [..............................] - ETA: 37s - loss: 0.3600 - accuracy: 0.9167"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quanhongjin/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857/858 [============================>.] - ETA: 0s - loss: 0.3356 - accuracy: 0.9208\n",
      "Epoch 2: val_loss improved from 0.47459 to 0.28364, saving model to models/lstm.h5\n",
      "858/858 [==============================] - 38s 45ms/step - loss: 0.3360 - accuracy: 0.9207 - val_loss: 0.2836 - val_accuracy: 0.9375\n",
      "Epoch 3/30\n",
      "857/858 [============================>.] - ETA: 0s - loss: 0.2345 - accuracy: 0.9508\n",
      "Epoch 3: val_loss improved from 0.28364 to 0.23547, saving model to models/lstm.h5\n",
      "858/858 [==============================] - 37s 43ms/step - loss: 0.2346 - accuracy: 0.9507 - val_loss: 0.2355 - val_accuracy: 0.9454\n",
      "Epoch 4/30\n",
      "858/858 [==============================] - ETA: 0s - loss: 0.1863 - accuracy: 0.9619\n",
      "Epoch 4: val_loss improved from 0.23547 to 0.20500, saving model to models/lstm.h5\n",
      "858/858 [==============================] - 37s 44ms/step - loss: 0.1863 - accuracy: 0.9619 - val_loss: 0.2050 - val_accuracy: 0.9546\n",
      "Epoch 5/30\n",
      "857/858 [============================>.] - ETA: 0s - loss: 0.1554 - accuracy: 0.9702\n",
      "Epoch 5: val_loss improved from 0.20500 to 0.17963, saving model to models/lstm.h5\n",
      "858/858 [==============================] - 37s 44ms/step - loss: 0.1553 - accuracy: 0.9703 - val_loss: 0.1796 - val_accuracy: 0.9651\n",
      "Epoch 6/30\n",
      "858/858 [==============================] - ETA: 0s - loss: 0.1420 - accuracy: 0.9728\n",
      "Epoch 6: val_loss improved from 0.17963 to 0.15219, saving model to models/lstm.h5\n",
      "858/858 [==============================] - 37s 44ms/step - loss: 0.1420 - accuracy: 0.9728 - val_loss: 0.1522 - val_accuracy: 0.9704\n",
      "Epoch 7/30\n",
      "858/858 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.9727\n",
      "Epoch 7: val_loss improved from 0.15219 to 0.13331, saving model to models/lstm.h5\n",
      "858/858 [==============================] - 37s 44ms/step - loss: 0.1362 - accuracy: 0.9727 - val_loss: 0.1333 - val_accuracy: 0.9730\n",
      "Epoch 8/30\n",
      "858/858 [==============================] - ETA: 0s - loss: 0.1169 - accuracy: 0.9788\n",
      "Epoch 8: val_loss did not improve from 0.13331\n",
      "858/858 [==============================] - 37s 43ms/step - loss: 0.1169 - accuracy: 0.9788 - val_loss: 0.1443 - val_accuracy: 0.9697\n",
      "Epoch 9/30\n",
      "858/858 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9826\n",
      "Epoch 9: val_loss improved from 0.13331 to 0.13264, saving model to models/lstm.h5\n",
      "858/858 [==============================] - 37s 43ms/step - loss: 0.0996 - accuracy: 0.9826 - val_loss: 0.1326 - val_accuracy: 0.9724\n",
      "Epoch 10/30\n",
      "858/858 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.9809\n",
      "Epoch 10: val_loss did not improve from 0.13264\n",
      "858/858 [==============================] - 39s 45ms/step - loss: 0.1012 - accuracy: 0.9809 - val_loss: 0.1598 - val_accuracy: 0.9618\n",
      "Epoch 11/30\n",
      "858/858 [==============================] - ETA: 0s - loss: 0.1292 - accuracy: 0.9732\n",
      "Epoch 11: val_loss improved from 0.13264 to 0.11961, saving model to models/lstm.h5\n",
      "858/858 [==============================] - 38s 45ms/step - loss: 0.1292 - accuracy: 0.9732 - val_loss: 0.1196 - val_accuracy: 0.9717\n",
      "Epoch 12/30\n",
      "857/858 [============================>.] - ETA: 0s - loss: 0.0744 - accuracy: 0.9869\n",
      "Epoch 12: val_loss did not improve from 0.11961\n",
      "858/858 [==============================] - 37s 43ms/step - loss: 0.0744 - accuracy: 0.9869 - val_loss: 0.1380 - val_accuracy: 0.9658\n",
      "Epoch 13/30\n",
      "857/858 [============================>.] - ETA: 0s - loss: 0.0732 - accuracy: 0.9877\n",
      "Epoch 13: val_loss improved from 0.11961 to 0.05889, saving model to models/lstm.h5\n",
      "858/858 [==============================] - 38s 44ms/step - loss: 0.0732 - accuracy: 0.9878 - val_loss: 0.0589 - val_accuracy: 0.9928\n",
      "Epoch 14/30\n",
      "858/858 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.9810\n",
      "Epoch 14: val_loss did not improve from 0.05889\n",
      "858/858 [==============================] - 37s 43ms/step - loss: 0.0956 - accuracy: 0.9810 - val_loss: 0.1445 - val_accuracy: 0.9684\n",
      "Epoch 15/30\n",
      "858/858 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 0.9841\n",
      "Epoch 15: val_loss did not improve from 0.05889\n",
      "858/858 [==============================] - 36s 42ms/step - loss: 0.0851 - accuracy: 0.9841 - val_loss: 0.0648 - val_accuracy: 0.9888\n",
      "Epoch 16/30\n",
      "857/858 [============================>.] - ETA: 0s - loss: 0.0436 - accuracy: 0.9942\n",
      "Epoch 16: val_loss did not improve from 0.05889\n",
      "858/858 [==============================] - 36s 42ms/step - loss: 0.0435 - accuracy: 0.9942 - val_loss: 0.0683 - val_accuracy: 0.9895\n",
      "Epoch 17/30\n",
      "857/858 [============================>.] - ETA: 0s - loss: 0.0915 - accuracy: 0.9824\n",
      "Epoch 17: val_loss did not improve from 0.05889\n",
      "858/858 [==============================] - 36s 42ms/step - loss: 0.0915 - accuracy: 0.9824 - val_loss: 0.0834 - val_accuracy: 0.9809\n",
      "Epoch 18/30\n",
      "857/858 [============================>.] - ETA: 0s - loss: 0.0679 - accuracy: 0.9885\n",
      "Epoch 18: val_loss did not improve from 0.05889\n",
      "858/858 [==============================] - 37s 43ms/step - loss: 0.0679 - accuracy: 0.9885 - val_loss: 0.1045 - val_accuracy: 0.9789\n",
      "Epoch 19/30\n",
      "857/858 [============================>.] - ETA: 0s - loss: 0.0612 - accuracy: 0.9890\n",
      "Epoch 19: val_loss improved from 0.05889 to 0.05575, saving model to models/lstm.h5\n",
      "858/858 [==============================] - 38s 44ms/step - loss: 0.0612 - accuracy: 0.9890 - val_loss: 0.0558 - val_accuracy: 0.9882\n",
      "Epoch 20/30\n",
      "857/858 [============================>.] - ETA: 0s - loss: 0.0642 - accuracy: 0.9884\n",
      "Epoch 20: val_loss did not improve from 0.05575\n",
      "858/858 [==============================] - 38s 44ms/step - loss: 0.0642 - accuracy: 0.9884 - val_loss: 0.0899 - val_accuracy: 0.9822\n",
      "Epoch 21/30\n",
      "858/858 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9916\n",
      "Epoch 21: val_loss did not improve from 0.05575\n",
      "858/858 [==============================] - 37s 43ms/step - loss: 0.0527 - accuracy: 0.9916 - val_loss: 0.0923 - val_accuracy: 0.9836\n",
      "Epoch 22/30\n",
      "857/858 [============================>.] - ETA: 0s - loss: 0.0658 - accuracy: 0.9880\n",
      "Epoch 22: val_loss did not improve from 0.05575\n",
      "858/858 [==============================] - 38s 44ms/step - loss: 0.0658 - accuracy: 0.9880 - val_loss: 0.0738 - val_accuracy: 0.9836\n",
      "Epoch 23/30\n",
      "858/858 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9915\n",
      "Epoch 23: val_loss did not improve from 0.05575\n",
      "858/858 [==============================] - 38s 45ms/step - loss: 0.0491 - accuracy: 0.9915 - val_loss: 0.0604 - val_accuracy: 0.9868\n",
      "Epoch 24/30\n",
      "858/858 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.9888\n",
      "Epoch 24: val_loss did not improve from 0.05575\n",
      "858/858 [==============================] - 39s 45ms/step - loss: 0.0626 - accuracy: 0.9888 - val_loss: 0.0722 - val_accuracy: 0.9842\n",
      "Epoch 25/30\n",
      "857/858 [============================>.] - ETA: 0s - loss: 0.0554 - accuracy: 0.9904\n",
      "Epoch 25: val_loss did not improve from 0.05575\n",
      "858/858 [==============================] - 39s 45ms/step - loss: 0.0554 - accuracy: 0.9904 - val_loss: 0.0591 - val_accuracy: 0.9882\n",
      "Epoch 26/30\n",
      "858/858 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9961\n",
      "Epoch 26: val_loss did not improve from 0.05575\n",
      "858/858 [==============================] - 39s 45ms/step - loss: 0.0309 - accuracy: 0.9961 - val_loss: 0.0680 - val_accuracy: 0.9868\n",
      "Epoch 27/30\n",
      "857/858 [============================>.] - ETA: 0s - loss: 0.0696 - accuracy: 0.9862\n",
      "Epoch 27: val_loss did not improve from 0.05575\n",
      "858/858 [==============================] - 39s 45ms/step - loss: 0.0697 - accuracy: 0.9862 - val_loss: 0.1048 - val_accuracy: 0.9763\n",
      "Epoch 28/30\n",
      "857/858 [============================>.] - ETA: 0s - loss: 0.0631 - accuracy: 0.9880\n",
      "Epoch 28: val_loss improved from 0.05575 to 0.04726, saving model to models/lstm.h5\n",
      "858/858 [==============================] - 38s 44ms/step - loss: 0.0631 - accuracy: 0.9881 - val_loss: 0.0473 - val_accuracy: 0.9901\n",
      "Epoch 29/30\n",
      "857/858 [============================>.] - ETA: 0s - loss: 0.0330 - accuracy: 0.9943\n",
      "Epoch 29: val_loss did not improve from 0.04726\n",
      "858/858 [==============================] - 39s 45ms/step - loss: 0.0330 - accuracy: 0.9943 - val_loss: 0.0618 - val_accuracy: 0.9882\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857/858 [============================>.] - ETA: 0s - loss: 0.0483 - accuracy: 0.9910\n",
      "Epoch 30: val_loss did not improve from 0.04726\n",
      "858/858 [==============================] - 39s 45ms/step - loss: 0.0483 - accuracy: 0.9909 - val_loss: 0.0672 - val_accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import argparse\n",
    "import warnings\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TimeDistributed, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import kapre\n",
    "from kapre.composed import get_melspectrogram_layer\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# models\n",
    "def Conv1D(N_CLASSES=10, SR=16000, DT=1.0):\n",
    "    input_shape = (int(SR*DT), 1)\n",
    "    i = get_melspectrogram_layer(input_shape=input_shape,\n",
    "                                 n_mels=128,\n",
    "                                 pad_end=True,\n",
    "                                 n_fft=512,\n",
    "                                 win_length=400,\n",
    "                                 hop_length=160,\n",
    "                                 sample_rate=SR,\n",
    "                                 return_decibel=True,\n",
    "                                 input_data_format='channels_last',\n",
    "                                 output_data_format='channels_last')\n",
    "    x = LayerNormalization(axis=2, name='batch_norm')(i.output)\n",
    "    x = TimeDistributed(layers.Conv1D(8, kernel_size=(4), activation='tanh'), name='td_conv_1d_tanh')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_1')(x)\n",
    "    x = TimeDistributed(layers.Conv1D(16, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_1')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_2')(x)\n",
    "    x = TimeDistributed(layers.Conv1D(32, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_2')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_3')(x)\n",
    "    x = TimeDistributed(layers.Conv1D(64, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_3')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_4')(x)\n",
    "    x = TimeDistributed(layers.Conv1D(128, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_4')(x)\n",
    "    x = layers.GlobalMaxPooling2D(name='global_max_pooling_2d')(x)\n",
    "    x = layers.Dropout(rate=0.1, name='dropout')(x)\n",
    "    x = layers.Dense(64, activation='relu', activity_regularizer=l2(0.001), name='dense')(x)\n",
    "    o = layers.Dense(N_CLASSES, activation='softmax', name='softmax')(x)\n",
    "    model = Model(inputs=i.input, outputs=o, name='1d_convolution')\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def Conv2D(N_CLASSES=10, SR=16000, DT=1.0):\n",
    "    input_shape = (int(SR*DT), 1)\n",
    "    i = get_melspectrogram_layer(input_shape=input_shape,\n",
    "                                 n_mels=128,\n",
    "                                 pad_end=True,\n",
    "                                 n_fft=512,\n",
    "                                 win_length=400,\n",
    "                                 hop_length=160,\n",
    "                                 sample_rate=SR,\n",
    "                                 return_decibel=True,\n",
    "                                 input_data_format='channels_last',\n",
    "                                 output_data_format='channels_last')\n",
    "    x = LayerNormalization(axis=2, name='batch_norm')(i.output)\n",
    "    x = layers.Conv2D(8, kernel_size=(7,7), activation='tanh', padding='same', name='conv2d_tanh')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_1')(x)\n",
    "    x = layers.Conv2D(16, kernel_size=(5,5), activation='relu', padding='same', name='conv2d_relu_1')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_2')(x)\n",
    "    x = layers.Conv2D(16, kernel_size=(3,3), activation='relu', padding='same', name='conv2d_relu_2')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_3')(x)\n",
    "    x = layers.Conv2D(32, kernel_size=(3,3), activation='relu', padding='same', name='conv2d_relu_3')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_4')(x)\n",
    "    x = layers.Conv2D(32, kernel_size=(3,3), activation='relu', padding='same', name='conv2d_relu_4')(x)\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    x = layers.Dropout(rate=0.2, name='dropout')(x)\n",
    "    x = layers.Dense(64, activation='relu', activity_regularizer=l2(0.001), name='dense')(x)\n",
    "    o = layers.Dense(N_CLASSES, activation='softmax', name='softmax')(x)\n",
    "    model = Model(inputs=i.input, outputs=o, name='2d_convolution')\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def LSTM(N_CLASSES=10, SR=16000, DT=1.0):\n",
    "    input_shape = (int(SR*DT), 1)\n",
    "    i = get_melspectrogram_layer(input_shape=input_shape,\n",
    "                                     n_mels=128,\n",
    "                                     pad_end=True,\n",
    "                                     n_fft=512,\n",
    "                                     win_length=400,\n",
    "                                     hop_length=160,\n",
    "                                     sample_rate=SR,\n",
    "                                     return_decibel=True,\n",
    "                                     input_data_format='channels_last',\n",
    "                                     output_data_format='channels_last',\n",
    "                                     name='2d_convolution')\n",
    "    x = LayerNormalization(axis=2, name='batch_norm')(i.output)\n",
    "    x = TimeDistributed(layers.Reshape((-1,)), name='reshape')(x)\n",
    "    s = TimeDistributed(layers.Dense(64, activation='tanh'),\n",
    "                        name='td_dense_tanh')(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(32, return_sequences=True),\n",
    "                             name='bidirectional_lstm')(s)\n",
    "    x = layers.concatenate([s, x], axis=2, name='skip_connection')\n",
    "    x = layers.Dense(64, activation='relu', name='dense_1_relu')(x)\n",
    "    x = layers.MaxPooling1D(name='max_pool_1d')(x)\n",
    "    x = layers.Dense(32, activation='relu', name='dense_2_relu')(x)\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    x = layers.Dropout(rate=0.2, name='dropout')(x)\n",
    "    x = layers.Dense(32, activation='relu',\n",
    "                         activity_regularizer=l2(0.001),\n",
    "                         name='dense_3_relu')(x)\n",
    "    o = layers.Dense(N_CLASSES, activation='softmax', name='softmax')(x)\n",
    "    model = Model(inputs=i.input, outputs=o, name='long_short_term_memory')\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, wav_paths, labels, sr, dt, n_classes,\n",
    "                 batch_size=32, shuffle=True):\n",
    "        self.wav_paths = wav_paths\n",
    "        self.labels = labels\n",
    "        self.sr = sr\n",
    "        self.dt = dt\n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = True\n",
    "        self.on_epoch_end()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.wav_paths) / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        wav_paths = [self.wav_paths[k] for k in indexes]\n",
    "        labels = [self.labels[k] for k in indexes]\n",
    "\n",
    "        # generate a batch of time data\n",
    "        X = np.empty((self.batch_size, int(self.sr*self.dt), 1), dtype=np.float32)\n",
    "        Y = np.empty((self.batch_size, self.n_classes), dtype=np.float32)\n",
    "\n",
    "        for i, (path, label) in enumerate(zip(wav_paths, labels)):\n",
    "            rate, wav = wavfile.read(path)\n",
    "            X[i,] = wav.reshape(-1, 1)\n",
    "            Y[i,] = to_categorical(label, num_classes=self.n_classes)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.wav_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    src_root = args.src_root\n",
    "    sr = args.sample_rate\n",
    "    dt = args.delta_time\n",
    "    batch_size = args.batch_size\n",
    "    model_type = args.model_type\n",
    "    params = {'N_CLASSES':len(os.listdir(args.src_root)),\n",
    "              'SR':sr,\n",
    "              'DT':dt}\n",
    "    models = {'conv1d':Conv1D(**params),\n",
    "              'conv2d':Conv2D(**params),\n",
    "              'lstm':  LSTM(**params)}\n",
    "    assert model_type in models.keys(), '{} not an available model'.format(model_type)\n",
    "    csv_path = os.path.join('logs', '{}_history.csv'.format(model_type))\n",
    "\n",
    "    wav_paths = glob('{}/**'.format(src_root), recursive=True)\n",
    "    wav_paths = [x.replace(os.sep, '/') for x in wav_paths if '.wav' in x]\n",
    "    classes = sorted(os.listdir(args.src_root))\n",
    "    le = LabelEncoder()\n",
    "    le.fit(classes)\n",
    "    labels = [os.path.split(x)[0].split('/')[-1] for x in wav_paths]\n",
    "    labels = le.transform(labels)\n",
    "    wav_train, wav_val, label_train, label_val = train_test_split(wav_paths,\n",
    "                                                                  labels,\n",
    "                                                                  test_size=0.1,\n",
    "                                                                  random_state=0)\n",
    "\n",
    "    assert len(label_train) >= args.batch_size, 'Number of train samples must be >= batch_size'\n",
    "    if len(set(label_train)) != params['N_CLASSES']:\n",
    "        warnings.warn('Found {}/{} classes in training data. Increase data size or change random_state.'.format(len(set(label_train)), params['N_CLASSES']))\n",
    "    if len(set(label_val)) != params['N_CLASSES']:\n",
    "        warnings.warn('Found {}/{} classes in validation data. Increase data size or change random_state.'.format(len(set(label_val)), params['N_CLASSES']))\n",
    "\n",
    "    tg = DataGenerator(wav_train, label_train, sr, dt,\n",
    "                       params['N_CLASSES'], batch_size=batch_size)\n",
    "    vg = DataGenerator(wav_val, label_val, sr, dt,\n",
    "                       params['N_CLASSES'], batch_size=batch_size)\n",
    "    model = models[model_type]\n",
    "    cp = ModelCheckpoint('models/{}.h5'.format(model_type), monitor='val_loss',\n",
    "                         save_best_only=True, save_weights_only=False,\n",
    "                         mode='auto', save_freq='epoch', verbose=1)\n",
    "    csv_logger = CSVLogger(csv_path, append=False)\n",
    "    model.fit(tg, validation_data=vg,\n",
    "              epochs=30, verbose=1,\n",
    "              callbacks=[csv_logger, cp])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Audio Classification Training')\n",
    "    parser.add_argument('--model_type', type=str, default='lstm',\n",
    "                        help='model to run. i.e. conv1d, conv2d, lstm')\n",
    "    \n",
    "    # replace with your absolute file path here\n",
    "    parser.add_argument('--src_root', type=str, default='/Users/quanhongjin/Documents/Cornell Tech/CS5785/Porject/clean',\n",
    "                        help='directory of audio files in total duration')\n",
    "    parser.add_argument('--batch_size', type=int, default=16,\n",
    "                        help='batch size')\n",
    "    parser.add_argument('--delta_time', '-dt', type=float, default=1.0,\n",
    "                        help='time in seconds to sample audio')\n",
    "    parser.add_argument('--sample_rate', '-sr', type=int, default=16000,\n",
    "                        help='sample rate of clean audio')\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    train(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb864b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbimporter\n",
      "  Downloading nbimporter-0.3.4-py3-none-any.whl (4.9 kB)\n",
      "Installing collected packages: nbimporter\n",
      "Successfully installed nbimporter-0.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nbimporter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6338493a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
